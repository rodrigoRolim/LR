---
título: "resultados"
authors: "RODRIGO ROLIM VERAS, ALBINO BOGUCHESKI JUNIOR, MARCOS ANTONIO NESPOLO JUNIOR"
date: "2024-04-09"
output: pdf_document
---

#TRABALHO DE IAA003 – Linguagem R

# EQUIPE: 23
# ALBINO BOGUCHESKI JUNIOR
# BEATRIZ LEANDRO BONAFINI
# CICERO SAMUEL RODRIGUES MENDES
# FERNANDA BATISTA DE OLIVEIRA
# MARCOS ANTONIO NESPOLO JUNIOR
# RODRIGO ROLIM VERAS

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### 1.1 Carregue a base de dados Satellite

```{r}
# instalar o pacotes necessários
install.packages("mlbench", repos = "http://cran.us.r-project.org")
install.packages("e1017", repos = "http://cran.us.r-project.org")
install.packages("randomForest", repos = "http://cran.us.r-project.org")
install.packages("kernlab", repos = "http://cran.us.r-project.org")
install.packages("caret", repos = "http://cran.us.r-project.org")
```

```{r}
# usar os pacotes necessários
library(mlbench)
library(caret)
```

```{r}
# carregar os dados Satellite
data(Satellite)
```

```{r}
# exibir estrutura dos dados Satellite
str(Satellite)
```

```{r}
# apresentar alguma medidas estatísticas do dados Satellite
summary(Satellite)
```

```{r}
# exibir alguns dados do Satellite
head(Satellite, n = 6)
```

#### 1.2 Crie partições contendo 80% para treino e 20% para teste

```{r}
# Para reproductibilidade
set.seed(7)
```

```{r}
# particionar em 80% para treino e 20% para teste
indices <- createDataPartition(Satellite$classes, p=0.8, list=F)
treino <- Satellite[indices, ]
teste <- Satellite[-indices, ]
```

#### 1.3 Treine modelos RandomForest, SVM e RNA para predição destes dados.

```{r}
# treinar modelos RandomForest, SVM e RNA
rf <- train(classes ~ ., data=treino, method="rf")
svm <- train(classes ~ ., data=treino, method="svmRadial")
rna <- train(classes ~ ., data=treino, method="nnet", trace=F)
```

#### 1.4 Escolha o melhor modelo com base em suas matrizes de confusão.

```{r}
# predições
predict.rf <- predict(rf, teste)
predict.svm <- predict(svm, teste)
predict.rna <- predict(rna, teste)
```

```{r}
# matrizes de confusões de cada uma das predições

# matriz de confusão para o modelo RF
conf_matrix.rf <- confusionMatrix(predict.rf, teste$classes)

print(conf_matrix.rf)
cat('\n')

# matriz de confusão para o modelo SVM
conf_matrix.svm <- confusionMatrix(predict.svm, teste$classes)

print(conf_matrix.svm)
cat('\n')

# matriz de confusão para o modelo RNA
conf_matrix.rna <- confusionMatrix(predict.rna, teste$classes)

print(conf_matrix.rna)
cat('\n')
```

#### 1.5 Indique qual modelo dá o melhor o resultado e a métrica utilizada

O melhor modelo foi random forest com acurácia de 0.9182 e kappa de 0.8987. A métrica utilizada foram a acurácia e kappa.

#### 2.1 Carregar o arquivo Volumes.csv (<http://www.razer.net.br/datasets/Volumes.csv>)

```{r}
dados <- read.csv("http://www.razer.net.br/datasets/Volumes.csv", sep=";", dec=",")
head(dados)
```

#### 2.2 Eliminar a coluna NR, que só apresenta um número sequencial

```{r}
dados$NR <- NULL
```

#### 2.3 Criar partição de dados: treinamento 80%, teste 20%

```{r}
regression.indices <- caret::createDataPartition(dados$VOL, p=0.8, list=F)
regression.treino <- dados[regression.indices, ]
regression.teste <- dados[-regression.indices, ]
```

#### 2.4 Usando o pacote "caret", treinar os modelos: Random Forest (rf), SVM (svmRadial), Redes Neurais (neuralnet) e o modelo alométrico de SPURR

```{r}
# Para reproductibilidade
set.seed(7)
```

```{r}
regression.rf <- caret::train(VOL ~ ., data=regression.treino, method="rf")
regression.svm <- caret::train(VOL ~ ., data=regression.treino, method="svmRadial")
regression.rna <- caret::train(
  VOL ~ ., data=regression.treino, 
  method="nnet", 
  trControl=trainControl(method = "LOOCV"), 
  trace=F
)
```

##### treino do modelo Spurr

```{r}
regression.spurr <- nls(
  VOL ~ b0 + b1*DAP*DAP*HT, 
  data=regression.treino, 
  start=list(b0=0.5, b1=0.5)
)
```

##### visualizar os resultados de Spurr

```{r}
summary(regression.spurr)
```

#### 2.5 Efetue as predições nos dados de teste

predições

```{r}
# Para reproductibilidade
set.seed(7)
```

```{r}
predict.regression.rf <- predict(regression.rf, regression.teste)
predict.regression.svm <- predict(regression.svm, regression.teste)
predict.regression.rna <- predict(regression.rna, regression.teste)
predict.regression.suprr <- predict(regression.spurr, regression.teste)
```

#### 2.6 Crie suas próprias funções (UDF) e calcule as seguintes métricas entre a predição e os dados observados

-   Erro padrão de estimativa: Syx

```{r}
Syx <- function(reals, predicteds, n) {
  return (sqrt(sum((reals - predicteds)^2)/(n - 2)))
}
```

-   Erro padrão de estimativa em porcentagem: Syx%

```{r}
SyxPercent <- function(reals, predicteds, n) {
  return ((Syx(reals, predicteds, n)/mean(reals))*100)
}
```

-   Coeficientededeterminação:R2

```{r}
R2 <- function (reals, predicteds) {
  return (1 - sum((reals - predicteds)^2)/sum((reals - mean(reals))^2))
}

```

#### 2.7 Escolha o melhor modelo.

##### métrica de estimativas para o modelo RandomForest - Regressão

-   coeficiente de determinação

```{r}
R2(regression.teste$VOL, predict.regression.rf)
```

-   Erro padrão estimativa

```{r}
n <- nrow(regression.teste)
Syx(regression.teste$VOL, predict.regression.rf, n)
```

-   Erro padrão estimativa em porcentagem

```{r}
n <- nrow(regression.teste)
SyxPercent(regression.teste$VOL, predict.regression.rf, n)
```

##### métrica de estimativas para o modelo SVM - Regressão

-   coeficiente de determinação

```{r}
R2(regression.teste$VOL, predict.regression.svm)
```

-   Erro padrão estimativa

```{r}
n <- nrow(regression.teste)
Syx(regression.teste$VOL, predict.regression.svm, n)
```

-   Erro padrão estimativa em porcentagem

```{r}
n <- nrow(regression.teste)
SyxPercent(regression.teste$VOL, predict.regression.svm, n)
```

##### métricas de estimativas para o modelo nnet - Regressão

-   coeficiente de determinação

```{r}
R2(regression.teste$VOL, predict.regression.rna)
```

-   Erro padrão estimativa

```{r}
n <- nrow(regression.teste)
Syx(regression.teste$VOL, predict.regression.rna, n)
```

-   Erro padrão estimativa em porcentagem

```{r}
n <- nrow(regression.teste)
SyxPercent(regression.teste$VOL, predict.regression.rna, n)
```

##### métricas de estimativas para o modelo Spurr

-   coeficiente de determinação

```{r}
R2(regression.teste$VOL, predict.regression.suprr)
```

-   Erro padrão estimativa

```{r}
n <- nrow(regression.teste)
Syx(regression.teste$VOL, predict.regression.suprr, n)
```

-   Erro padrão estimativa em porcentagem

```{r}
n <- nrow(regression.teste)
SyxPercent(regression.teste$VOL, predict.regression.suprr, n)
```

##### 2.7 escolha o melhor modelo

##### Resumo dos resultados

###### RF:

1.  coeficiente de determinação: 0.8223603.
2.  Erro padrão estimativa: 0.1376052.
3.  Erro padrão estimativa em porcentagem: 10.42195

###### SVM:

1.  coeficiente de determinação: 0.6254546
2.  Erro padrão estimativa: 0.19981
3.  Erro padrão estimativa em porcentagem: 15.13322

###### nnet:

1.  coeficiente de determinação: -1.069672
2.  Erro padrão estimativa: 0.4696948
3.  Error padrão estimativa em porcentagem: 35.57377

###### spurr:

1.  coeficiente de determinação: 0.7734018
2.  Erro padrão estimativa: 0.1554151
3.  Error padrão estimativa em porcentagem: 11.77084

Com base nas métricas, o modelo que se saiu melhor foi o RandomForest, com R2 igual 0.8223603, Erro padrão estimativa de 0.1376052 e Erro padrão de estima- tiva em porcentagem de 10.42195
